import streamlit as st
import pandas as pd
import os
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from janome.tokenizer import Tokenizer

def run_app():

    # ãƒšãƒ¼ã‚¸è¨­å®š
    st.set_page_config(page_title="ãŠã—ãˆã¦ã­ã“ã¡ã‚ƒã‚“", layout="wide")

    tokenizer = Tokenizer()

    def tokenize(text):
        return " ".join(tokenizer.tokenize(str(text), wakati=True))

    def get_combined_texts(df):
        return (
            df["CDISC Submission Value-J"].fillna("") + " " +
            df["NCI Preferred Term-J"].fillna("") + " " +
            df["CDISC Synonym(s)-J"].fillna("") + " " +
            df["CDISC Submission Value"].fillna("")
        )

    @st.cache_data
    def load_excel_data():
        # dataã®ãƒ‘ã‚¹ã‚’å–å¾—
        current_dir = os.path.dirname(__file__)
        excel_path = os.path.join(current_dir, "..", "data", "02.Terminology_V3.3_å’Œè¨³ä»˜ã.xlsx")

        # Excelãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã‚·ãƒ¼ãƒˆã”ã¨ã«èª­ã¿è¾¼ã‚€
        index = pd.read_excel(excel_path, sheet_name="ãƒšã‚¢ä»¥å¤–")
        data = pd.read_excel(excel_path, sheet_name="ãƒšã‚¢ã®ãªã„Terminologyå’Œè¨³ä»˜ã")
        return index, data

    def clear_search():
        st.session_state.search_word = ""
        st.session_state.search_mode = None

    def run_terminology_app():
        st.title("ğŸ±ã•ãŒã—ã¦ã­ã“ã¡ã‚ƒã‚“ SDTMIG V3.3 Terminologyæ¤œç´¢")

        try:
            sheet_index, sheet_data = load_excel_data()
        except Exception as e:
            st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return

        # çŠ¶æ…‹åˆæœŸåŒ–
        if "search_mode" not in st.session_state:
            st.session_state.search_mode = None

        if "search_word" not in st.session_state:
            st.session_state.search_word = ""

        # Terminologyé¸æŠ
        term_list = sheet_index["Term"].dropna().unique().tolist()

        selected_term = st.selectbox(
            "ğŸ“‚ Terminologyã‚’é¸ã‚“ã§ãã ã•ã„",
            term_list,
            key="term_selector",
            on_change=clear_search
        )

        # æ¤œç´¢èªã¨ãƒœã‚¿ãƒ³
        st.session_state.search_word = st.text_input("ğŸ” æ¤œç´¢èªã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", value=st.session_state.search_word)

        col1, col2, col3 = st.columns(3)
        if col1.button("ğŸ§  ãŠã™ã™ã‚æ¤œç´¢ï¼ˆAIã‚½ãƒ¼ãƒˆï¼‰"):
            st.session_state.search_mode = "ai"
        if col2.button("ğŸ¯ ãƒ”ãƒ³ãƒã‚¤ãƒ³ãƒˆæ¤œç´¢ï¼ˆå®Œå…¨ä¸€è‡´ï¼‰"):
            st.session_state.search_mode = "exact"
        if col3.button("ğŸ” ã‚†ã‚‹ã£ã¨æ¤œç´¢ï¼ˆéƒ¨åˆ†ä¸€è‡´ï¼‰"):
            st.session_state.search_mode = "partial"

        # ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
        df_filtered = sheet_data[sheet_data["Term"] == selected_term].copy()

        # æ¤œç´¢ãƒ¢ãƒ¼ãƒ‰åˆ¥å‡¦ç†
        keyword = st.session_state.search_word.strip()

        if keyword and st.session_state.search_mode == "ai":
            texts = get_combined_texts(df_filtered).tolist()
            tokenized_texts = [tokenize(t) for t in texts]
            tokenized_keyword = tokenize(keyword)

            vectorizer = TfidfVectorizer(max_features=1000)
            tfidf_matrix = vectorizer.fit_transform(tokenized_texts + [tokenized_keyword])
            similarity = cosine_similarity(tfidf_matrix[-1], tfidf_matrix[:-1]).flatten()

            df_filtered["é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢"] = similarity
            df_filtered = df_filtered.sort_values("é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢", ascending=False)

            st.write(f"ğŸ” é¡ä¼¼åº¦é †ã« {len(df_filtered)} ä»¶ã®çµæœ")

        elif keyword and st.session_state.search_mode == "exact":
            mask = df_filtered.apply(lambda row: any(str(keyword).lower() == str(v).lower() for v in row.values), axis=1)
            df_filtered = df_filtered[mask]
            st.write(f"ğŸ¯ å®Œå…¨ä¸€è‡´ã§ {len(df_filtered)} ä»¶ãƒ’ãƒƒãƒˆ")

        elif keyword and st.session_state.search_mode == "partial":
            mask = df_filtered.apply(lambda row: any(keyword.lower() in str(v).lower() for v in row.values), axis=1)
            df_filtered = df_filtered[mask]
            st.write(f"ğŸ§© éƒ¨åˆ†ä¸€è‡´ã§ {len(df_filtered)} ä»¶ãƒ’ãƒƒãƒˆ")

        elif not keyword:
            st.info("ğŸ” æ¤œç´¢èªãŒæœªå…¥åŠ›ãªã®ã§ã€é¸æŠã—ãŸTerminologyã®å€™è£œä¸€è¦§ã‚’è¡¨ç¤ºã—ã¾ã™")

        # è¡¨ç¤ºåˆ—
        display_columns = [
            "Code", "CDISC Submission Value", "CDISC Submission Value-J",
            "CDISC Synonym(s)-J", "CDISC Definition-J", "NCI Preferred Term-J",
            "CDISC Synonym(s)", "CDISC Definition", "NCI Preferred Term", "é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢"
        ]
        display_cols = [c for c in display_columns if c in df_filtered.columns]

        st.dataframe(df_filtered[display_cols], use_container_width=True)

        if st.button("â† ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã«æˆ»ã‚‹"):
            st.session_state["selected_app"] = "menu"
    run_terminology_app()

if __name__ == "__main__":
    run_app()